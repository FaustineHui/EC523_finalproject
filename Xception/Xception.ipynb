{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK-bD7QFSthm",
        "outputId": "8a5ab9b2-23c2-4711-f795-f5157ef5cc40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "from functools import reduce\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torchvision import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.dpi'] = 200\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chi72zEfSthn"
      },
      "source": [
        "**Inputs**: \n",
        "- `path_to_train`: Path to your training set folder\n",
        "- `path_to_test`: Path to your test set folder\n",
        "- `num_workers`: number of subprocesses to use for data loading\n",
        "- `batch_size`: how many samples per batch to load\n",
        "- `valid_size`: percentage of training set to use as validation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oRjKrO8SSthn"
      },
      "outputs": [],
      "source": [
        "\n",
        "def TrainConstructor(path_to_train, path_to_valid, num_workers=4, batch_size=32):\n",
        "    \n",
        "  \n",
        "    # Transformations to the image, edit as need be\n",
        "    transform = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Resize([299,299]),\n",
        "        transforms.ToTensor()])\n",
        "    \n",
        "    train_dataset = datasets.ImageFolder(path_to_train, transform=transform)\n",
        "    print(\"Successfully Loaded Training Set.\")\n",
        "\n",
        "    valid_dataset = datasets.ImageFolder(path_to_valid, transform=transform)\n",
        "    print(\"Successfully Loaded Validation Set.\")\n",
        "\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True)\n",
        "\n",
        "    train_category = path_to_train.split('/')[-1]\n",
        "\n",
        "    return train_loader, valid_loader, train_category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQidUwiWStho",
        "outputId": "ba152022-b6cf-49ff-9dcd-eeb2c100c96b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully Loaded Training Set.\n",
            "Successfully Loaded Test Set.\n",
            "Number of Classes: 2\n"
          ]
        }
      ],
      "source": [
        "train_loader, valid_loader, train_category = TrainConstructor(path_to_train='/content/drive/MyDrive/EC523DATA/train/airplane',path_to_valid='',num_workers=2, batch_size=16)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JpYhrvwlStho"
      },
      "source": [
        "## Confirmation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpD10XG7Sthp"
      },
      "outputs": [],
      "source": [
        "# helper function to un-normalize and display an image\n",
        "# def imshow(img):\n",
        "# #     img = img / 2 + 0.5  # unnormalize if you added normalization in the transformation step\n",
        "#     plt.imshow(np.transpose(img, (1, 2, 0)))  # convert from Tensor image\n",
        "\n",
        "# # obtain one batch of training images\n",
        "# dataiter = iter(train_loader)\n",
        "# images, labels = dataiter.next()\n",
        "# images = images.numpy() # convert images to numpy for display\n",
        "# print(images.shape)\n",
        "\n",
        "# # plot the images in the batch, along with the corresponding labels\n",
        "# fig = plt.figure(figsize=(25, 4))\n",
        "# # display 20 images\n",
        "# for idx in np.arange(20):\n",
        "#     ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "#     imshow(images[idx])\n",
        "#     ax.set_title(classes[labels[idx]])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSDefrnHSthp"
      },
      "source": [
        "## Define the Model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vWQjuTk0Sthp"
      },
      "outputs": [],
      "source": [
        "\n",
        "class SeparableConv2d(nn.Module):\n",
        "    def __init__(self,in_channels,out_channels,kernel_size=1,stride=1,padding=0,dilation=1,bias=False):\n",
        "        super(SeparableConv2d,self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels,in_channels,kernel_size,stride,padding,dilation,groups=in_channels,bias=bias)\n",
        "        self.pointwise = nn.Conv2d(in_channels,out_channels,1,1,0,1,1,bias=bias)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.pointwise(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self,in_filters,out_filters,reps,strides=1,start_with_relu=True,grow_first=True):\n",
        "        super(Block, self).__init__()\n",
        "\n",
        "        if out_filters != in_filters or strides!=1:\n",
        "            self.skip = nn.Conv2d(in_filters,out_filters,1,stride=strides, bias=False)\n",
        "            self.skipbn = nn.BatchNorm2d(out_filters)\n",
        "        else:\n",
        "            self.skip=None\n",
        "\n",
        "        rep=[]\n",
        "\n",
        "        filters=in_filters\n",
        "        if grow_first:\n",
        "            rep.append(nn.ReLU(inplace=True))\n",
        "            rep.append(SeparableConv2d(in_filters,out_filters,3,stride=1,padding=1,bias=False))\n",
        "            rep.append(nn.BatchNorm2d(out_filters))\n",
        "            filters = out_filters\n",
        "\n",
        "        for i in range(reps-1):\n",
        "            rep.append(nn.ReLU(inplace=True))\n",
        "            rep.append(SeparableConv2d(filters,filters,3,stride=1,padding=1,bias=False))\n",
        "            rep.append(nn.BatchNorm2d(filters))\n",
        "\n",
        "        if not grow_first:\n",
        "            rep.append(nn.ReLU(inplace=True))\n",
        "            rep.append(SeparableConv2d(in_filters,out_filters,3,stride=1,padding=1,bias=False))\n",
        "            rep.append(nn.BatchNorm2d(out_filters))\n",
        "\n",
        "        if not start_with_relu:\n",
        "            rep = rep[1:]\n",
        "        else:\n",
        "            rep[0] = nn.ReLU(inplace=False)\n",
        "\n",
        "        if strides != 1:\n",
        "            rep.append(nn.MaxPool2d(3,strides,1))\n",
        "        self.rep = nn.Sequential(*rep)\n",
        "\n",
        "    def forward(self,inp):\n",
        "        x = self.rep(inp)\n",
        "\n",
        "        if self.skip is not None:\n",
        "            skip = self.skip(inp)\n",
        "            skip = self.skipbn(skip)\n",
        "        else:\n",
        "            skip = inp\n",
        "\n",
        "        x+=skip\n",
        "        return x\n",
        "\n",
        "\n",
        "class Xception(nn.Module):\n",
        "    \"\"\"\n",
        "    Xception optimized for the ImageNet dataset, as specified in\n",
        "    https://arxiv.org/pdf/1610.02357.pdf\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=1000):\n",
        "        \"\"\" Constructor\n",
        "        Args:\n",
        "            num_classes: number of classes\n",
        "        \"\"\"\n",
        "        super(Xception, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3,2, 0, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32,64,3,bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        #do relu here\n",
        "\n",
        "        self.block1=Block(64,128,2,2,start_with_relu=False,grow_first=True)\n",
        "        self.block2=Block(128,256,2,2,start_with_relu=True,grow_first=True)\n",
        "        self.block3=Block(256,728,2,2,start_with_relu=True,grow_first=True)\n",
        "\n",
        "        self.block4=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "        self.block5=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "        self.block6=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "        self.block7=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "\n",
        "        self.block8=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "        self.block9=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "        self.block10=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "        self.block11=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
        "\n",
        "        self.block12=Block(728,1024,2,2,start_with_relu=True,grow_first=False)\n",
        "\n",
        "        self.conv3 = SeparableConv2d(1024,1536,3,1,1)\n",
        "        self.bn3 = nn.BatchNorm2d(1536)\n",
        "        self.relu3 = nn.ReLU(inplace=True)\n",
        "\n",
        "        #do relu here\n",
        "        self.conv4 = SeparableConv2d(1536,2048,3,1,1)\n",
        "        self.bn4 = nn.BatchNorm2d(2048)\n",
        "\n",
        "        self.fc = nn.Linear(2048, num_classes)\n",
        "\n",
        "        # #------- init weights --------\n",
        "        # for m in self.modules():\n",
        "        #     if isinstance(m, nn.Conv2d):\n",
        "        #         n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "        #         m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "        #     elif isinstance(m, nn.BatchNorm2d):\n",
        "        #         m.weight.data.fill_(1)\n",
        "        #         m.bias.data.zero_()\n",
        "        # #-----------------------------\n",
        "\n",
        "    def features(self, input):\n",
        "        x = self.conv1(input)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu2(x)\n",
        "\n",
        "        x = self.block1(x)\n",
        "        x = self.block2(x)\n",
        "        x = self.block3(x)\n",
        "        x = self.block4(x)\n",
        "        x = self.block5(x)\n",
        "        x = self.block6(x)\n",
        "        x = self.block7(x)\n",
        "        x = self.block8(x)\n",
        "        x = self.block9(x)\n",
        "        x = self.block10(x)\n",
        "        x = self.block11(x)\n",
        "        x = self.block12(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu3(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = self.bn4(x)\n",
        "        return x\n",
        "\n",
        "    def logits(self, features):\n",
        "        x = nn.ReLU(inplace=True)(features)\n",
        "\n",
        "        x = F.adaptive_avg_pool2d(x, (1, 1))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.last_linear(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.features(input)\n",
        "        x = self.logits(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def xception(num_classes=2):\n",
        "    model = Xception(num_classes=num_classes)\n",
        "    # TODO: ugly\n",
        "    model.last_linear = model.fc\n",
        "    del model.fc\n",
        "    return model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dSAW9BGtSthq"
      },
      "outputs": [],
      "source": [
        "model = xception(num_classes=2)\n",
        "model = nn.DataParallel(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oOzL-vcSthq"
      },
      "source": [
        "## Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_xbpAYSgSthq"
      },
      "outputs": [],
      "source": [
        "# specify loss function (categorical cross-entropy)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# specify optimizer\n",
        "optimizer = optimizer = torch.optim.SGD([\n",
        "    {'params': list(model.parameters())[:-1], 'lr': 1e-3, 'momentum': 0.9, 'weight_decay': 1e-3},\n",
        "    {'params': list(model.parameters())[-1], 'lr': 5e-5, 'momentum': 0.9, 'weight_decay': 1e-5}\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qO-HN6uvSthq"
      },
      "source": [
        "## Train\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HpVczYZSthr",
        "outputId": "c50c2314-705e-418c-b586-1d593f21a217"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 1 \tTraining Loss: 0.513509 \tValidation Loss: 0.241210\n",
            "\n",
            "Validation loss decreased (inf --> 0.241210).  Saving model ...\n",
            "Epoch: 2 \tTraining Loss: 0.506459 \tValidation Loss: 0.316797\n",
            "Epoch: 3 \tTraining Loss: 0.476894 \tValidation Loss: 0.218464\n",
            "\n",
            "Validation loss decreased (0.241210 --> 0.218464).  Saving model ...\n",
            "Epoch: 4 \tTraining Loss: 0.448503 \tValidation Loss: 0.201057\n",
            "\n",
            "Validation loss decreased (0.218464 --> 0.201057).  Saving model ...\n",
            "Epoch: 5 \tTraining Loss: 0.410734 \tValidation Loss: 0.155885\n",
            "\n",
            "Validation loss decreased (0.201057 --> 0.155885).  Saving model ...\n",
            "Epoch: 6 \tTraining Loss: 0.349661 \tValidation Loss: 0.289827\n",
            "Epoch: 7 \tTraining Loss: 0.263097 \tValidation Loss: 0.089868\n",
            "\n",
            "Validation loss decreased (0.155885 --> 0.089868).  Saving model ...\n",
            "Epoch: 8 \tTraining Loss: 0.194744 \tValidation Loss: 0.138800\n",
            "Epoch: 9 \tTraining Loss: 0.139783 \tValidation Loss: 0.064925\n",
            "\n",
            "Validation loss decreased (0.089868 --> 0.064925).  Saving model ...\n",
            "Epoch: 10 \tTraining Loss: 0.099610 \tValidation Loss: 0.047343\n",
            "\n",
            "Validation loss decreased (0.064925 --> 0.047343).  Saving model ...\n",
            "Epoch: 11 \tTraining Loss: 0.074494 \tValidation Loss: 0.022029\n",
            "\n",
            "Validation loss decreased (0.047343 --> 0.022029).  Saving model ...\n",
            "Epoch: 12 \tTraining Loss: 0.052601 \tValidation Loss: 0.008877\n",
            "\n",
            "Validation loss decreased (0.022029 --> 0.008877).  Saving model ...\n",
            "Epoch: 13 \tTraining Loss: 0.038721 \tValidation Loss: 0.007406\n",
            "\n",
            "Validation loss decreased (0.008877 --> 0.007406).  Saving model ...\n",
            "Epoch: 14 \tTraining Loss: 0.035182 \tValidation Loss: 0.009263\n",
            "Epoch: 15 \tTraining Loss: 0.020272 \tValidation Loss: 0.010950\n",
            "Epoch: 16 \tTraining Loss: 0.027373 \tValidation Loss: 0.022956\n",
            "Epoch: 17 \tTraining Loss: 0.017712 \tValidation Loss: 0.008376\n",
            "Epoch: 18 \tTraining Loss: 0.012705 \tValidation Loss: 0.009275\n",
            "Epoch: 19 \tTraining Loss: 0.015887 \tValidation Loss: 0.002187\n",
            "\n",
            "Validation loss decreased (0.007406 --> 0.002187).  Saving model ...\n",
            "Epoch: 20 \tTraining Loss: 0.010117 \tValidation Loss: 0.006469\n",
            "Epoch: 21 \tTraining Loss: 0.013386 \tValidation Loss: 0.004857\n",
            "Epoch: 22 \tTraining Loss: 0.008815 \tValidation Loss: 0.045004\n",
            "Epoch: 23 \tTraining Loss: 0.009064 \tValidation Loss: 0.012978\n",
            "Epoch: 24 \tTraining Loss: 0.005896 \tValidation Loss: 0.004262\n",
            "Epoch: 25 \tTraining Loss: 0.004701 \tValidation Loss: 0.002692\n",
            "Epoch: 26 \tTraining Loss: 0.007465 \tValidation Loss: 0.005301\n",
            "Epoch: 27 \tTraining Loss: 0.008153 \tValidation Loss: 0.013338\n",
            "Epoch: 28 \tTraining Loss: 0.005227 \tValidation Loss: 0.007616\n",
            "Epoch: 29 \tTraining Loss: 0.007160 \tValidation Loss: 0.007269\n",
            "Epoch: 30 \tTraining Loss: 0.010308 \tValidation Loss: 0.002154\n",
            "\n",
            "Validation loss decreased (0.002187 --> 0.002154).  Saving model ...\n"
          ]
        }
      ],
      "source": [
        "# number of epochs to train the model\n",
        "n_epochs = 30\n",
        "\n",
        "valid_loss_min = np.Inf # track change in validation loss\n",
        "training_vis = []\n",
        "valid_vis = []\n",
        "\n",
        "for epoch in range(1, n_epochs+1):\n",
        "\n",
        "    # keep track of training and validation loss\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "    \n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    model.train()\n",
        "    for data, target in train_loader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        \n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "\n",
        "        \n",
        "    ######################    \n",
        "    # validate the model #\n",
        "    ######################\n",
        "    model.eval()\n",
        "    for data, target in valid_loader:\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        \n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # update average validation loss \n",
        "        valid_loss += loss.item()*data.size(0)\n",
        "        \n",
        "    # calculate average losses\n",
        "    train_loss = train_loss/len(train_loader.dataset)\n",
        "    valid_loss = valid_loss/len(valid_loader.dataset)\n",
        "    \n",
        "    training_vis.append(train_loss)\n",
        "    valid_vis.append(valid_loss)\n",
        "    \n",
        "    # print training/validation statistics \n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
        "        epoch, train_loss, valid_loss))\n",
        "    \n",
        "    # save model if validation loss has decreased\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print('\\nValidation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
        "        valid_loss_min,\n",
        "        valid_loss))\n",
        "        torch.save(model.state_dict(), 'Xception_' + train_category + '.pt')\n",
        "        valid_loss_min = valid_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fupHYKtKSthr",
        "outputId": "36173362-1e01-43af-cc52-03acbaad2f0b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# model = TheModelClass(*args, **kwargs)\n",
        "model.load_state_dict(torch.load('Xception35656_gan-detector_Final.pt'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def TestConstructor(path_to_test, num_workers=4, batch_size=32):\n",
        "    \n",
        "  \n",
        "    # Transformations to the image, edit as need be\n",
        "    transform = transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Resize([299,299]),\n",
        "        transforms.ToTensor()])\n",
        "\n",
        "    test_dataset = datasets.ImageFolder(path_to_test, transform=transform)\n",
        "    print(\"Successfully Loaded Test Set.\")\n",
        "    \n",
        "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, \n",
        "        num_workers=num_workers)\n",
        "    if classes != None:\n",
        "        print(\"Number of Classes:\", len(classes))\n",
        "    return test_loader, classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13lEpUTWSthr",
        "outputId": "2210fde7-28cc-4a84-ff4e-8a30f6f4f1f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Loss: 0.004518\n",
            "\n",
            "Test Accuracy of  Real: 100% (23/23)\n",
            "Test Accuracy of  Fake: 100% (17/17)\n",
            "\n",
            "Test Accuracy (Overall): 100% (40/40)\n"
          ]
        }
      ],
      "source": [
        "test_categories = ['airplane','bicycle','bird','bottle','bus','car','cat','chair','cow','diningtable','dog','horse','motorbike','person','pottedplant','sheep','sofa','train','tvmonitor']\n",
        "\n",
        "for i in range(20):\n",
        "    test_loader, classes = TestConstructor(path_to_test='/content/drive/MyDrive/EC523DATA/testairplane/airplane/' + test_categories[i], classes=['Real','Fake'],num_workers=2, batch_size=16)\n",
        "\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    # track test loss\n",
        "    test_loss = 0.0\n",
        "    class_correct = list(0. for i in range(2))\n",
        "    class_total = list(0. for i in range(2))\n",
        "\n",
        "    model.eval()\n",
        "    # iterate over test data\n",
        "    for data, target in test_loader:\n",
        "    #     print(target)\n",
        "        # move tensors to GPU if CUDA is available\n",
        "        if train_on_gpu:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "    #     print(output)\n",
        "        # calculate the batch loss\n",
        "        loss = criterion(output, target)\n",
        "        # update test loss \n",
        "        test_loss += loss.item()*data.size(0)\n",
        "        # convert output probabilities to predicted class\n",
        "        _, pred = torch.max(output, 1)\n",
        "    #     print(pred)\n",
        "        # compare predictions to true label\n",
        "        correct_tensor = pred.eq(target.data.view_as(pred))\n",
        "        correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "        # calculate test accuracy for each object class\n",
        "        for i in range(2):\n",
        "    #         print(i)\n",
        "            label = target.data[i]\n",
        "            class_correct[label] += correct[i].item()\n",
        "            class_total[label] += 1\n",
        "            \n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    # average test loss\n",
        "    test_loss = test_loss/len(test_loader.dataset)\n",
        "    print('Test Loss for' + test_categories[i] + ': {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "    for i in range(2):\n",
        "        if class_total[i] > 0:\n",
        "            print('Test Accuracy of %5s for' + test_categories[i] + ': %2d%% (%2d/%2d)' % (\n",
        "                classes[i], 100 * class_correct[i] / class_total[i],\n",
        "                np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "        else:\n",
        "            print('Test Accuracy of %5s for' + test_categories[i] + ': N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "    print('\\nTest Accuracy (Overall) for' + test_categories[i] + ': %2d%% (%2d/%2d)' % (\n",
        "        100. * np.sum(class_correct) / np.sum(class_total),\n",
        "        np.sum(class_correct), np.sum(class_total)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqZ4esj6Sths"
      },
      "source": [
        "## Visualize Model Performance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "NMYu3n94Sths",
        "outputId": "3e6c1bb9-1c8c-4c00-c89a-4affba90a3b1"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f32a4051f5eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_vis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_vis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_vis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_vis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Xception_line.svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'training_vis' is not defined"
          ]
        }
      ],
      "source": [
        "plt.plot(range(30), training_vis)\n",
        "plt.scatter(range(epoch), training_vis)\n",
        "plt.scatter(range(epoch), valid_vis)\n",
        "plt.plot(range(epoch), valid_vis)\n",
        "plt.savefig('Xception_line.svg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdPRmnwbSths"
      },
      "source": [
        "#### **Save the Training and Validation Losses**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W486DuY8Sths"
      },
      "outputs": [],
      "source": [
        "np.savetxt('Xception_85.txt', np.array([training_vis, valid_vis]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35xGmpW4Sths"
      },
      "source": [
        "## Visualize Misclassified"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UCsjaSqSths"
      },
      "outputs": [],
      "source": [
        "# obtain one batch of test images\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# get sample outputs\n",
        "output = model(images)\n",
        "# convert output probabilities to predicted class\n",
        "_, preds = torch.max(output, 1)\n",
        "# prep images for display\n",
        "images = images.numpy()\n",
        "labels = labels.numpy()\n",
        "print(images.shape)\n",
        "# plot the images in the batch, along with predicted and true labels\n",
        "fig = plt.figure(figsize=(20, 4))\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "    ax.imshow(np.swapaxes((images[idx]),axis1=0, axis2=2))\n",
        "    ax.set_title(\"{} ({})\".format(classes[preds[idx]], classes[labels[idx]]),\n",
        "                 color=(\"green\" if classes[preds[idx]]==classes[labels[idx]] else \"red\"))\n",
        "    \n",
        "plt.savefig('Xception_mis.pdf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSPvDeqESths"
      },
      "source": [
        "## Bonus Sanity Check Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmSp-0xwSths"
      },
      "outputs": [],
      "source": [
        "rgb_img = np.squeeze(images[3])\n",
        "channels = ['red channel', 'green channel', 'blue channel']\n",
        "\n",
        "fig = plt.figure(figsize = (36, 36)) \n",
        "for idx in np.arange(rgb_img.shape[0]):\n",
        "    ax = fig.add_subplot(1, 3, idx + 1)\n",
        "    img = rgb_img[idx]\n",
        "    ax.imshow(img, cmap='gray')\n",
        "    ax.set_title(channels[idx])\n",
        "    width, height = img.shape\n",
        "    thresh = img.max()/2.5\n",
        "    for x in range(width):\n",
        "        for y in range(height):\n",
        "            val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
        "            ax.annotate(str(val), xy=(y,x),\n",
        "                    horizontalalignment='center',\n",
        "                    verticalalignment='center', size=8,\n",
        "                    color='white' if img[x][y]<thresh else 'black')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "Xception_new.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
